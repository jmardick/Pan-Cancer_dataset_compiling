---
title: "PROJECT_NAME"
subtitle: "MasSpec Pen Data Preprocessing + LASSO Model"
author: "`r Sys.info()[['user']]`"
date: "`r format(Sys.time(), '%B %d, %Y %H:%M')`"
knit: (function(inputFile, encoding) { 
      proj_name <- tools::file_path_sans_ext(basename(inputFile));
      out_dir <- paste0(Sys.Date(), "_", proj_name);
      if(!file.exists(out_dir)) {   dir.create(out_dir) };
      rmarkdown::render(inputFile,
                        encoding=encoding, 
                        output_file=file.path(dirname(inputFile), 
                        out_dir, 
                        paste0(format(Sys.time(), "%Y-%m-%d_%H.%M"),"_", proj_name, ".pdf"))) 
                        })
header-includes:
  - \usepackage{titling}
  - \setlength{\droptitle}{-1in}

  - \pretitle{\begin{center}\LARGE} 
  - \posttitle{\par\end{center}\vskip -0.2in}
 
  - \preauthor{\begin{center}\large \vskip -0.2in}
  - \postauthor{\par\end{center}}
  
  - \predate{\begin{center}\large \vskip -0.2in} 
  - \postdate{\par\end{center}}

  - \usepackage{floatrow}
  - \usepackage[labelformat = empty]{caption}
  
  - \usepackage[x11names]{xcolor}
  
output: 
  pdf_document:
    keep_tex: FALSE
    extra_dependencies: "subfig"
geometry: "left=0.5in, right=0.5in, top=0.5in, bottom=0.5in"
---

\footskip = -0.1in
\vspace{-1cm}
```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, echo = FALSE, cache = TRUE)
## cache set to TRUE because sometimes otherwise the files directory disappears for some users
```

```{r libraries, message = FALSE, warning = FALSE}
library(rmarkdown)
library(knitr)
library(kableExtra)
library(ggpubr)

library(tidyverse)
library(reshape2)
library(readxl)
library(rawrr)
library(sqldf)

library(stringr)
library(doParallel)
library(fcluster)
library(johnfuncs)

library(caret) ## automates supervised learning (predictive modeling)
library(glmnet) ## for training, cross validation, and testing model
library(pROC) ## for plotting ROC curve
library(scales) ## for integer y-axis on histogram
```

```{r user input}
## Full path to folder with sample files (excel or csv, or raw Thermo files)
## PASTE PATH IN BETWEEN INNER PARENTHASIS WITH QUOTES ON THE OUTSIDE -- NO NEED TO CHANGE BACKSLASHES TO FORWARD SLASHES
#sample_dir <- gsub("\\\\", "/", r"(C:\Users\fjackobs\Desktop\MSPen_script_test_data\csv)")
#sample_dir <- gsub("\\\\", "/", r"(C:\Users\fjackobs\Desktop\MSPen_script_test_data\xlsx)")
sample_dir <- gsub("\\\\", "/", r"(C:\Users\kezia\OneDrive\Documents\Brain OR project\Anna\Annas data redone\NLvsMG_Data)")

## Full path to feature list, otherwise NA
#feature_file <- gsub("\\\\", "/", r"(C:\Users\fjackobs\FEATURE_FILE.csv)")
feature_file <- NA
#feature_file <- gsub("\\\\", "/", r"(C:\Users\fjackobs\OneDrive - Baylor College of Medicine\01_Eberlin_Lab\03_My-Code-Scripts\R\MDACC_Ovarian\DESI Prostate Annotations adjusted - Neg.csv)")

## Full path to background peak list, otherwise NA
#background_file <- gsub("\\\\", "/", r"(C:\Users\fjackobs\BACKGROUND_FILE.csv)")
#background_file <- NA
background_file <- gsub("\\\\", "/", r"(C:\Users\kezia\OneDrive\Documents\Brain OR project\Anna\Annas data redone\BG file\bg5.8.18RMBrainSpecies.csv)")

## ---------------------------------------------------------------------------

## Scan numbers to import when using raw Thermo files
scans <- 1
#scans <- 50:500 ## number of scans to extract from each raw file

## Mass range to filter
mass_range <- c(100,1000)

## Peak Alignment Method: "clustering", "binning", or "featurelist"
peak_alignment_method <- "clustering"

## If peak alignment method is "clustering":
clust_h <- 0.005 ## Height at which to cut dendrogram to determine clusters

## If peak alignment method is "featurelist":
ppm_error <- 5 ## Mass error tolerance of sample peaks to match to feature peaks

## Normalization Method: "tic", "maxpeak", "median", "medianlog", or "none"
normalization_method <- "tic" 

## ---------------------------------------------------------------------------

## Fraction of samples to use for training model
train_fraction <- 0.7
```

```{r create output directory, include = FALSE}
proj_name <- tools::file_path_sans_ext(basename(rstudioapi::getSourceEditorContext()$path))

out_dir <- paste0(Sys.Date(), "_", proj_name)

if(!file.exists(out_dir)) {   dir.create(out_dir) }

files_dir <- paste0(format(Sys.time(), "%Y-%m-%d_%H.%M"), "_", proj_name, "_files")

if(!file.exists(file.path(out_dir,files_dir))) {   dir.create(file.path(out_dir,files_dir)) }
```

```{r other settings}
## Signal-to-Noise Ratio Threshold
SNR_thresh <-  2

## Peak filter
p <- 0.10 ## A peak present in fewer than p*100% of samples is removed, default = 0.10 or 10%

## Randomization seed
seed <- 1234
```

```{r classes}
## read sub-directories for class names
classes <- gsub(file.path(sample_dir, "/"), "", list.dirs(sample_dir, recursive=FALSE), fixed=TRUE)
```

```{r file extension}
sample_file_ext <- unique(unlist(
  lapply(classes, function(x) 
    tools::file_ext(list.files(file.path(sample_dir, "/",x,"/"))))))[1] 
## only take the first file extension type...tbd if more than one type in folder
```

```{r file names}
file_name_list <- lapply(classes, function(x) 
  list.files(path = file.path(sample_dir,x), pattern = paste0("*.", sample_file_ext), full.names = TRUE))

## Ensure patient ordering is consistent across different OSes.
file_name_list <- lapply(file_name_list, sort)
```

```{r sample names}
sample_names_list <- lapply(file_name_list, function(x) tools::file_path_sans_ext(basename(x)))
names(sample_names_list) <- classes

sample_names <- unlist(sample_names_list)

sample_names_df <- purrr::map_df(sample_names_list, ~as.data.frame(.x), .id="id")
colnames(sample_names_df) <- c("class", "sample_name")
```

```{r csv data}
if (sample_file_ext == "csv") {
  fixed_objects <- list(mass_range = mass_range, SNR_thresh = SNR_thresh)
  
  spectra_list <- nested_process_csv(file_name_list, fixed_objects)
  
  ## Set sample names and classes of spectra_list
  spectra_list <- lapply(seq_along(spectra_list), \(i) setNames(spectra_list[[i]], sample_names_list[[i]]))
  names(spectra_list) <- classes
}
```

```{r excel data}
if (sample_file_ext == "xlsx") {
  fixed_objects <- list(mass_range = mass_range, SNR_thresh = SNR_thresh)
  
  spectra_list <- nested_process_xlsx(file_name_list, fixed_objects)
  
  ## Set sample names and classes of spectra_list
  spectra_list <- lapply(seq_along(spectra_list), \(i) setNames(spectra_list[[i]], sample_names_list[[i]]))
  names(spectra_list) <- classes
}
```

```{r raw Thermo data}
## If sample files are raw Thermo
if (sample_file_ext == "raw") {
  fixed_objects <- list(scans = scans, mass_range = mass_range, SNR_thresh = SNR_thresh)
  
  spectra_list <- nested_process_raw_thermo(file_name_list, fixed_objects)
  
  ## Set sample names and classes of spectra_list
  spectra_list <- lapply(seq_along(spectra_list), \(i) setNames(spectra_list[[i]], sample_names_list[[i]]))
  names(spectra_list) <- classes
}
```

```{r peak alignment clustering}
## If peak alignment method is clustering
if (peak_alignment_method == "clustering") {
  
  clust_int_method  <-  "sumints" ## Handling of multiple intensities aggregating to one cluster centroid: "sumints" or "maxint"
  
  all_mz <- spectra_list %>%
    flatten() %>%
    map(~ round(.x$m.z, 3)) %>%
    unlist() %>%
    sort()
  
  ## Cluster peaks into centroids
  tree <- fcluster(all_mz)
  clust_mz <- fcutree(all_mz, tree, h=clust_h)
  clustMZ <- sort(clust_mz$cen)
  
  ## Match cluster centroids to sample peaks
  clusterMatrixList <- lapply(spectra_list, function(x, y, z, w) 
    get_cluster_matrix(x, y, z, w), y=clustMZ, z = clust_h, w = clust_int_method)
  
  preprocList <- lapply(clusterMatrixList, function(x) as.matrix(get_data_matrix_clustering(x)))
  
  aligned_spectra <- do.call(rbind, preprocList)
  
  colnames(aligned_spectra) <- clustMZ
  rownames(aligned_spectra) <- sample_names
  
  ## FILTER #3: REMOVE RARE/UNCOMMON PEAKS PRESENT < 10% SAMPLES
  mz_count_filter <- colSums(aligned_spectra != 0) > as.integer(nrow(aligned_spectra)*p)
  aligned_spectra <- aligned_spectra[, mz_count_filter]
  
  filtered_mz <- clustMZ[mz_count_filter]
  
  centroid_min_max <- identify_clusters(clust_mz, all_mz)
  
  ## FILTER #4: REMOVE BACKGROUND PEAKS (IF BACKGROUND FILE PRESENT)
  if (!is.na(background_file)) {
    ## Read background file, check if it has a header
    if(is.character(read.csv(background_file, header = FALSE, nrows = 1)[1,1]) == TRUE) {
      bg_mz <- read.csv(background_file, header = TRUE)
    } else {
      bg_mz <- read.csv(background_file, header = FALSE)
    }
    
    colnames(bg_mz) <- "mz"
    
    # match bg_mz to cluster centroid
    bg_centroids <- sqldf("SELECT centroid_min_max.centroid, bg_mz.*
          FROM bg_mz,centroid_min_max
          WHERE bg_mz.mz BETWEEN centroid_min_max.min_mz AND centroid_min_max.max_mz")
    
    ## Remove peaks from aligned_spectra that are in bg_mz_centroid
    bg_ind <- which(filtered_mz %in% unique(bg_centroids$centroid))
    
    filtered_mz <- filtered_mz[-c(bg_ind)]
    aligned_spectra <- aligned_spectra[, -c(bg_ind)]
  }
}
```

```{r peak alignment binning}
if (peak_alignment_method == "binning") {
  ## Hard coded that m/z values are rounded to 2 decimal places and intensities of peaks that fall into the same bin are summed (by John Lin). 
  ## TBD about changing this - FEJ 2024-09-06
  
  all_mz <- spectra_list %>%
    flatten() %>%
    map(~ round(.x$m.z, 2)) %>% ## round to 2 decimal places
    unlist() %>%
    sort() 
  
  ## FILTER #3: REMOVE RARE/UNCOMMON PEAKS PRESENT < 10% SAMPLES
  mz_count <- table(all_mz)
  mz_count_filter <- mz_count > as.integer(length(sample_names)*p)
  filtered_mz <- as.numeric(names(mz_count)[mz_count_filter])
  
  ## Bin sample peaks
  preprocList <- lapply(spectra_list, function(x,z) get_data_matrix_binning(x,z), z=filtered_mz)
  
  aligned_spectra <- do.call(rbind, preprocList)
  
  colnames(aligned_spectra) <- filtered_mz
  rownames(aligned_spectra) <- sample_names
  
  ## FILTER #4: REMOVE BACKGROUND PEAKS (IF BACKGROUND FILE PRESENT)
  if (!is.na(background_file)) {
    ## Read background file, check if it has a header
    if(is.character(read.csv(background_file, header = FALSE, nrows = 1)[1,1]) == TRUE) {
      bg_mz <- round(read.csv(background_file, header = TRUE),2)
    } else {
      bg_mz <- round(read.csv(background_file, header = FALSE), 2)
    } ## round to 2 decimal places for binned values
    
    aligned_spectra <- aligned_spectra[, !(colnames(aligned_spectra) %in% bg_mz)]
    filtered_mz <- as.numeric(colnames(aligned_spectra))
  }
  
  centroid_min_max <- NA
}
```

```{r peak alignment feature list}
if (peak_alignment_method == "featurelist") {
  background_file <- NA
  
  ## Read file with feature peaks
  feature_df <- read.csv(feature_file, header = TRUE)
  feature_peaks <- feature_df[,1]
  
  ## Feature mz plus/minus instrument mass error, round to 3 decimal places
  mass_error <- (ppm_error * feature_peaks)/1e6
  
  feature_peaks <- data.frame(feature_mz = feature_peaks,
                              mass_error = mass_error,
                              mass_error_lower = round(feature_peaks - mass_error,3),
                              mass_error_upper = round(feature_peaks + mass_error,3))
  
  ## fixed objects for exporting to parallel computing
  fixed_objects <- list(feature_peaks = feature_peaks)
  
  feature_matched_spectra <- nested_feature_peak_alignment(spectra_list, fixed_objects)
  
  ## turn list of lists into dataframe
  feature_matched_spectra <- lapply(feature_matched_spectra, function(x) x %>%
                                      reduce(full_join,by = "feature_mz")) %>% 
    reduce(full_join,by = "feature_mz")
  
  ## sort by target_mz
  feature_matched_spectra <- feature_matched_spectra[order(feature_matched_spectra$feature_mz), ]
  
  filtered_mz <- feature_matched_spectra$feature_mz
  
  ## feature_mass column to rownames
  feature_matched_spectra <- feature_matched_spectra %>% 
    remove_rownames %>% 
    column_to_rownames(var = "feature_mz") %>% 
    as.data.frame()
  
  ## Add sample names as column names
  colnames(feature_matched_spectra) <- sample_names
  
  ## Replace NA with 0
  feature_matched_spectra <- replace(feature_matched_spectra, is.na(feature_matched_spectra), 0)
  
  ## Transpose so rows are samples and columns are masses
  aligned_spectra <- t(feature_matched_spectra)
  
  ## remove columns that are only zeros
  zero_col <- which(colSums(aligned_spectra==0) == nrow(aligned_spectra))
  if (length(zero_col) != 0) {
    filtered_mz <- filtered_mz[-c(zero_col)]
    aligned_spectra <- aligned_spectra[, -c(zero_col)]
  }
  
  centroid_min_max <- NA
}
```

```{r normalization}
xall <- normalize_pixel(aligned_spectra, normalization_method)
```

```{r yall}
## create yall object 
yall <- foreach(i = 1:length(file_name_list), .combine = c) %do% {
  rep(i, length(file_name_list[[i]])) }

## factorize yall
yall <- factor(yall,levels=c("1","2"),labels = classes)
```

```{r remove samples with no peaks}
## remove samples that have no peaks (i.e., don't train with an empty spectrum)
na_rows <- rowSums(is.na(xall)) > 0
xall <- xall[!na_rows, ]
yall <- yall[!na_rows]
sample_names <- sample_names[!na_rows]
```

```{r Split Data into Training and Testing Sets}
## splitting based on response variables
set.seed(seed)
train_partition <- createDataPartition(
  yall,
  p = train_fraction,
  times = 2,
  list = TRUE )

train_index <- train_partition$Resample2

## create training set
xtrain <- xall[train_index, ]
ytrain <- yall[train_index]

## create testing set
xtest <- xall[-train_index, ]
ytest <- yall[-train_index]

sample_names_df$train_test_set <- ifelse(row_number(sample_names_df) %in% train_index, "train", "test")
```

```{r R data, include = FALSE}
save(list = ls(), 
     file=file.path(out_dir, files_dir, paste0(format(Sys.time(), "%Y-%m-%d_%H.%M"),"_",proj_name,"_preprocessed",  ".RData")))
```

```{r Training}
model <- glmnet(
  xtrain, 
  ytrain, 
  family = "binomial", ## for logit (logarithm of the odds) or logistic regression
  alpha = 1, ## for lasso
  standardize = FALSE, ## because intensities are already in same units
  lambda.min.ratio = 1e-05 ) ## The model will compute its own lambda sequence based on nlambda and lambda.min.ratio 
```

```{r Cross Validation}
## set number of folds
#nfolds <- 10
nfolds <- nrow(xtrain) ## leave-one-sample-out cross validation

set.seed(seed)
## cross validation
cvmodel <- cv.glmnet(
  xtrain, 
  ytrain, 
  nfolds = nfolds,
  type.measure = "class", ## loss to use for binomial cross-validation, gives misclassification error
  keep = TRUE, ## returns a prevalidated array containing fitted values for each observation and each value of lambda
  family = "binomial", ## for logit (logarithm of the odds) or logistic regression
  alpha = 1, ## for lasso
  standardize = FALSE, ## because intensities are already in same units
  lambda.min.ratio = 1e-05 )
```

```{r ROC Metrics}
## save index of lambda value that gives minimum cvm (mean cross-validated error)
min_lambda_index <- which(cvmodel$lambda == cvmodel$lambda.min)

## 1/(1+e^(-preval)) is the inverse of the link function?
cv_predictions <- 1/(1+exp(-cvmodel$fit.preval[,min_lambda_index]))

## build ROC for training data using minLamIdx
roc_curve <- roc(
  ytrain, 
  cv_predictions )

## create dataframe from ROC object to create plot for trade off
## of accuracy, sensitivity, and specificity
roc_df <- data.frame(
  cutoff = roc_curve$thresholds, 
  sensitivity = roc_curve$sensitivities, 
  specificity = roc_curve$specificities )

roc_df$accuracy <- (roc_df$sensitivity*length(roc_curve$cases) + 
                      roc_df$specificity*length(roc_curve$controls)) / (length(roc_curve$cases) + 
                                                                          length(roc_curve$controls) )

## plot trade off of accuracy, sensitivity, and specificity
roc_metrics <- ggplot(roc_df) + geom_line(aes(cutoff, sensitivity, col = "Sensitivity")) + 
  geom_line(aes(cutoff, specificity, col = "Specificity")) + 
  geom_line(aes(cutoff, accuracy, col = "Accuracy")) +
  labs(x = "cutoff", y = "%", color="") +
  ggtitle("Trade off of performance metrics for determining threshold cutoff value")
```

```{r Threshold Coordinates}
## Identify Threshold Coordinates where Accuracy, Sensitivity, and Specificity Cross
## Set threshold for labeling classes --> balance of true positive and false positive rates.
best_threshold <- as.double(coords(roc_curve, 
                                   "best", ## coordinates for best threshold value
                                   ret = "threshold", ## coordinates to return
                                   best.method = "youden" )[1,1]) ## optimal cut-off is the threshold that maximizes the distance to the identity (diagonal) line
```

```{r CV Confusion Matrix}
## predict classes based on threshold
cv_p_thresh <- ifelse(cv_predictions < best_threshold, classes[1], classes[2])

cv_p_class <- factor(cv_p_thresh, levels(ytrain))

## simple confusion matrix table
cv_cm <- table(True=ytrain,
               Predict=cv_p_class)
```

```{r Training Histogram}
train_df <- data.frame(file_name=sample_names[train_index], 
                       true_class=ytrain, 
                       prediction_class=cv_p_class, 
                       probability=cv_predictions)

rownames(train_df) <- NULL

train_wrong_preds <- train_df %>%
  filter(true_class != prediction_class)
```

```{r Report Model Coefficients}
coef <- reportCoef(xall, model, cvmodel$lambda.min, filtered_mz, classes)
```

```{r Testing}
test_p <- predict(model,
                  xtest,
                  s = cvmodel$lambda.min, ## Value of the penalty parameter lambda at which predictions are required
                  type = "response" ) ## to get prediction values rather than linker function values
```

```{r Testing Confusion Matrix}
test_p_thresh <- ifelse(test_p < best_threshold, classes[1], classes[2]) 
test_p_class <- factor(test_p_thresh, levels(ytest))

## simple confusion matrix table
test_cm <- table(True=ytest,
                 Predict=test_p_class)
```

```{r Test Histogram}
test_df <- data.frame(file_name=sample_names[-c(train_index)], 
                      true_class=ytest, 
                      prediction_class=test_p_class, 
                      probability=as.numeric(test_p))

rownames(test_df) <- NULL

test_wrong_preds <- test_df %>%
  filter(true_class != prediction_class)
```

```{r save model, include=FALSE}
save(scans, mass_range, peak_alignment_method, clust_h, ppm_error, normalization_method, seed, 
     classes, centroid_min_max, filtered_mz, 
     model, cvmodel, best_threshold, coef, 
     file=file.path(out_dir, files_dir, paste0(format(Sys.time(), "%Y-%m-%d_%H.%M"), "_", proj_name,"_model.RData")))
```

```{r save files, include = FALSE}
## training set files
write.csv(cv_cm, 
          file = file.path(out_dir, files_dir, "train_cm.csv"))

write.csv(train_df, 
          row.names = FALSE,
          file.path(out_dir, files_dir, "train_preds.csv"))

write.csv(train_wrong_preds, 
          row.names = FALSE,
          file.path(out_dir, files_dir, "misclassified_train_preds.csv"))

write.csv(coef, 
          file.path(out_dir, files_dir, "coefficients.csv"))

## test set files
write.csv(test_cm, 
          file = file.path(out_dir, files_dir, "test_cm.csv"))

write.csv(test_df, 
          row.names = FALSE,
          file.path(out_dir, files_dir, "test_preds.csv"))

write.csv(test_wrong_preds, 
          row.names = FALSE,
          file.path(out_dir, files_dir, "misclassified_test_preds.csv"))
```

```{r save plots, include=FALSE}
png(filename=file.path(out_dir, files_dir, "cv_plot.png"))
plot(cvmodel)
title("cross-validation curve : binomial family", line = 2.5)
dev.off()

png(filename=file.path(out_dir, files_dir, "roc_plot.png"))
plot(roc_curve, 
     print.thres="best", 
     print.thres.best.method="youden",
     print.auc=TRUE, 
     auc.polygon=TRUE,
     main = "ROC Curve")
dev.off()

ggsave(roc_metrics, filename = file.path(out_dir, files_dir, "roc_metrics_thresh.png"))
```

```{r settings table}
if (peak_alignment_method == "clustering") {
  cluster_bin_size <- c("Cluster Height:", clust_h)
} else if (peak_alignment_method == "binning") {
  cluster_bin_size <- c("Bin Size:", "0.01")
} else if (peak_alignment_method == "featurelist") {
  cluster_bin_size <- c("Peak Mass Error:", paste0(ppm_error, " ppm"))
}

if (is.na(background_file)) {
  bg_exclusion <- "no"
} else if (!is.na(background_file)) {
  bg_exclusion <- "yes"
}

settings_df <- rbind(#c("SNR Threshold:", SNR_thresh),
                     c("Mass Range (m/z):", paste0(mass_range[1], " - ", mass_range[2])),
                     c("Peak Alignment Method:", peak_alignment_method),
                     cluster_bin_size,
                     c("Background Peak Exclusion:", bg_exclusion),
                     c("Normalization Method:", normalization_method),
                     c("Randomization Seed:", seed),
                     c("Train/Test Split:", paste0((train_fraction*100),"/",(100-(train_fraction*100)))),
                     c("Elastic Net Alpha:", "1 (LASSO)"))

classes2 <- tools::toTitleCase(gsub("_", " ", classes)) ## Replace _ with space to make class names look nicer
#classes2 <- unlist(lapply(str_split(classes, pattern  = " "), tail, n = 1L)) ## If class is last element of full class name
#classes2 <- unlist(lapply(str_split(classes, pattern  = "_"), tail, n = 1L)) ## If class is last element of full class name

kable(settings_df,
      caption = "\\textbf{Preprocessing and Model Settings}",
      format = "latex",
      row.names = FALSE,
      align = "r",
      booktabs = TRUE,
      longtable = TRUE,
      linesep = "")

#cols <- rev(c(hue_pal()(2))) ## teal, salmon
cols <- c(hue_pal()(2)) ## salmon, teal
```

```{r fancy cm}
cv_cm2 <- as.data.frame.matrix(cv_cm) ## create new objects to not alter og cv_cm
test_cm2 <- as.data.frame.matrix(test_cm) ## create new objects to not alter og cv_cm

cv_cm2 <- cbind(c("True", "True"),
               classes2,
               cv_cm2)

test_cm2 <- cbind(c("True", "True"),
                 classes2,
                 test_cm2)

rownames(cv_cm2) <- NULL
rownames(test_cm2) <- NULL

colnames(cv_cm2) <- c("", " ", classes2)
colnames(test_cm2) <- c("", " ", classes2)

cv_accuracy <- rbind(c(paste0(classes2[1], " Recall: "), 
                       paste0(format(round((cv_cm2[1,3]/rowSums(cv_cm2[,3:4])[1])*100, 1), nsmall = 1), "%")),
                     c(paste0(classes2[2], " Recall: "), 
                       paste0(format(round((cv_cm2[2,4]/rowSums(cv_cm2[,3:4])[2])*100,1), nsmall = 1), "%")),
                     c("Overall Accuracy: ", 
                       paste0(format(round(((cv_cm2[1,3] + cv_cm2[2,4])/sum(cv_cm2[, 3:4]))*100, 1), nsmall = 1), "%")))

test_accuracy <- rbind(c(paste0(classes2[1], " Recall: "), 
                         paste0(format(round((test_cm2[1,3]/rowSums(test_cm2[,3:4])[1])*100, 1), nsmall = 1), "%")),
                       c(paste0(classes2[2], " Recall: "), 
                         paste0(format(round((test_cm2[2,4]/rowSums(test_cm2[,3:4])[2])*100,1), nsmall = 1), "%")),
                       c("Overall Accuracy: ", 
                         paste0(format(round(((test_cm2[1,3] + test_cm2[2,4])/sum(test_cm2[, 3:4]))*100, 1), nsmall = 1), "%")))

cv_cm2[1, 3] <- cell_spec(cv_cm2[1, 3], "latex", background = "Honeydew2")
cv_cm2[2, 4] <- cell_spec(cv_cm2[2, 4], "latex", background = "Honeydew2")

test_cm2[1, 3] <- cell_spec(test_cm2[1, 3], "latex", background = "Honeydew2")
test_cm2[2, 4] <- cell_spec(test_cm2[2, 4], "latex", background = "Honeydew2")
```

```{r coef rounding}
if(normalization_method == "median"){
  coef2 <- data.frame(cbind(c("Intercept", format(as.numeric(rownames(coef[2:nrow(coef),])), nsmall = 3)), 
                            as.numeric(coef[, 1])))
}else {
  coef2 <- data.frame(cbind(c("Intercept", format(as.numeric(rownames(coef[2:nrow(coef),])), nsmall = 3)),
                            format(round(as.numeric(coef[, 1]),3), nsmall = 3)))
}

colnames(coef2) <- c("Features", paste0("Weights (", classes2[2], ")"))
```

\newfloatcommand{btabbox}{table}

\begin{figure}[H]
\begin{floatrow}
\ffigbox{%
```{r train cm table, fig.align = "right"}
kable(cv_cm2,
      caption = "\\textbf{Training Set}",
      format = "latex",
      align = "r",
      booktabs = TRUE,
      longtable = TRUE,
      linesep = "",
      escape = FALSE) %>%
  kable_styling(full_width = FALSE) %>%
  add_header_above(c("", " ", "Predict" = 2)) %>%
  column_spec(2:4, width = "2.2cm") %>%
  collapse_rows(columns = 1)

kable(cv_accuracy,
      format = "latex",
      row.names = FALSE,
      align = "r",
      booktabs = TRUE,
      longtable = TRUE,
      linesep = "")
```
}{{}}

\btabbox{%
```{r test cm table, fig.align = "right"}
kable(test_cm2,
      caption = "\\textbf{Test Set}", 
      format = "latex",
      align = "r",
      booktabs = TRUE,
      longtable = TRUE,
      linesep = "",
      escape = FALSE) %>%
  kable_styling(full_width = FALSE) %>%
  add_header_above(c("", " ", "Predict" = 2)) %>%
  column_spec(2:4, width = "2.2cm") %>%
  collapse_rows(columns = 1)

kable(test_accuracy,
      format = "latex",
      row.names = FALSE,
      align = "r",
      booktabs = TRUE,
      longtable = TRUE,
      linesep = "")
```
}{{}}
\end{floatrow}
\end{figure}

\vspace{.5cm}
```{r roc curve report, fig.width=4, fig.height=4}
plot(roc_curve, 
     print.thres="best", 
     print.thres.best.method="youden",
     print.auc=TRUE, 
     auc.polygon=TRUE,
     main = "ROC")
```

\newpage
```{r split coefs into pos and neg}
## remove intercept row
intercept <- coef2[1, 2]

## split features into positive and negative
pos_features <- coef2[which(as.numeric(coef2[[2]]) > 0), ]
neg_features <- coef2[which(as.numeric(coef2[[2]]) < 0), ]

pos_features <- subset(pos_features, Features != "Intercept")
neg_features <- subset(neg_features, Features != "Intercept")

max_len <- max(nrow(pos_features), nrow(neg_features))

pos_features <- pos_features[c(NA, seq_len(nrow(pos_features)), rep(NA, max_len - nrow(pos_features))), ]
neg_features <- neg_features[c(NA, seq_len(nrow(neg_features)), rep(NA, max_len - nrow(neg_features))), ]
empty_col <- c(intercept, rep(NA, max_len))

split_coefs <- cbind(pos_features, empty_col, neg_features)

split_coefs[is.na(split_coefs)] <- ""

colnames(split_coefs) <- c(paste0(classes2[2], " Features"), paste0(classes2[2], " Weights"), "Intercept", paste0(classes2[1], " Features"), paste0(classes2[1], " Weights"))
```

```{r coefs table}
split_coefs %>%
  kable(
    caption = "\\textbf{Model Predictive Feature Weights}",
    row.names = FALSE,
    format = "latex",
    align = "rrcrr",
    booktabs = TRUE,
    longtable = TRUE,
    linesep = ""
  ) %>%
  kableExtra::kable_styling(
    latex_options = c("striped")
  ) %>%
  column_spec(1:2, width = "3.5cm")%>%
  column_spec(4:5, width = "3.5cm")
```

\vspace{.5cm}
```{r feature plot, fig.width=12, fig.height=3}
## head to tail bar plot of features and weights
if (normalization_method == "median"){
  max_y <- max(abs(as.numeric(coef2[2:nrow(coef2), 2])))
  min_y <- -1*max(abs(as.numeric(coef2[2:nrow(coef2), 2])))
} else {
  max_y <- round(max(abs(as.numeric(coef2[2:nrow(coef2), 2]))))
  min_y <- -1*round(max(abs(as.numeric(coef2[2:nrow(coef2), 2]))))
}

coef3 <- coef2 %>% 
  mutate(fill = ifelse(as.numeric(coef2[, 2]) < 0, classes2[1], classes2[2]))

coef3$fill <- factor(coef3$fill, levels = classes2)

coef3 <- coef3[-c(1), ]

coef_plot <- ggplot(coef3,
                    aes(x = as.numeric(Features), y = as.numeric(coef3[, 2]), fill = fill)) +
  geom_bar(stat = "identity", width = 2)+
  labs(y = "Weights", x = expression(italic("m/z"))) +
  coord_cartesian(xlim = mass_range, ylim = c(min_y, max_y)) +
  scale_x_continuous(breaks = seq(mass_range[1], mass_range[2], by = 50), expand = c(0.01,0)) +
  scale_y_continuous(limits = c(min_y, max_y), expand = c(0.01,0)) +
  scale_fill_manual(values = cols) + 
  ggtitle("Model Feature Weights") +
  theme_classic() + 
  guides(fill = guide_legend(byrow = TRUE)) +
  theme(legend.spacing.y = unit(1.0, 'in')) +
  theme(legend.position = c(1, 0.625),
        legend.justification = c("right", "top"),
        legend.box.just = "right",
        legend.margin = margin(6, 6, 6, 6),
        legend.title=element_blank(),
        legend.key.size = unit(0.2, 'in'),
        legend.background = element_rect(fill='transparent')) +
  geom_hline(yintercept=0)

coef_plot
```

\newpage
```{r train and test histograms, fig.width=8, fig.height=3}
train_plot <- ggplot(train_df, aes(x=probability, fill=true_class, color=true_class)) + 
  geom_histogram(binwidth=0.01, alpha=0.25, position="identity",boundary=0) + 
  ggtitle("Model Prediction Probabilities: Training Set") +
  geom_vline(xintercept = best_threshold, linewidth = 0.75,  color = "black", linetype = "dashed") +
  scale_x_continuous(breaks = seq(0, 1, by = 0.1), minor_breaks = seq(0, 1, by = 0.05), expand = c(0.05,0)) +
  scale_color_manual(values = cols, labels = c(classes2[1], classes2[2])) +
  scale_fill_manual(values = cols, labels = c(classes2[1], classes2[2])) +
  labs(x = "Prediction Probability", y = "Spectra Count", color="True Class", fill = "True Class") +
  theme_minimal(base_size = 9)

test_plot <- ggplot(test_df, aes(x=probability, fill=true_class, color=true_class)) + 
  geom_histogram(binwidth=0.01, alpha=0.25, position="identity",boundary=0) + 
  ggtitle("Model Prediction Probabilities: Test Set") +
  geom_vline(xintercept = best_threshold, linewidth = 0.75,  color = "black", linetype = "dashed") +
  scale_x_continuous(breaks = seq(0, 1, by = 0.1), minor_breaks = seq(0, 1, by = 0.05), expand = c(0.05,0)) +
  scale_color_manual(values = cols, labels = c(classes2[1], classes2[2])) +
  scale_fill_manual(values = cols, labels = c(classes2[1], classes2[2])) +
  labs(x = "Prediction Probability", y = "Spectra Count", color="True Class", fill = "True Class") +
  theme_minimal(base_size = 9)

ggarrange(train_plot, test_plot, common.legend = TRUE,
          legend = "bottom")
```

```{r save coef_plot and train and test histograms}
ggsave(plot=coef_plot, filename = file.path(out_dir, files_dir, "coef_plot.png"), 
       width = 12,
       height = 3,
       units = "in",
       dpi = 300)
ggsave(plot=train_plot, filename = file.path(out_dir, files_dir, "train_histogram.png"), bg = "white")
ggsave(plot=test_plot, filename = file.path(out_dir, files_dir, "test_histogram.png"), bg = "white")
```

```{r misclassified train and test samples}
## Add misclassified training samples
train_wrong_preds <- train_df %>%
  filter(true_class != prediction_class)

train_wrong_preds <- train_wrong_preds[order(train_wrong_preds$true_class), ]

train_wrong_preds$true_class <- gsub(classes[1], classes2[1], gsub(classes[2], classes2[2],train_wrong_preds$true_class))
train_wrong_preds$prediction_class <- gsub(classes[1], classes2[1], gsub(classes[2], classes2[2],train_wrong_preds$prediction_class))

train_wrong_preds$probability <- round(train_wrong_preds$probability, 3)

## Add misclassified test samples
test_wrong_preds <- test_df %>%
  filter(true_class != prediction_class)

test_wrong_preds <- test_wrong_preds[order(test_wrong_preds$true_class), ]

test_wrong_preds$true_class <- gsub(classes[1], classes2[1], gsub(classes[2], classes2[2],test_wrong_preds$true_class))
test_wrong_preds$prediction_class <- gsub(classes[1], classes2[1], gsub(classes[2], classes2[2],test_wrong_preds$prediction_class))

test_wrong_preds$probability <- round(test_wrong_preds$probability, 3)
```

```{r train wrong preds table}
kable(train_wrong_preds,
      caption = "\\textbf{Training Set Misclassifications}",
      col.names = c("Sample Name", "True Class", "Predicted Class", "Probability"),
      row.names = FALSE,
      format = "latex",
      align = "l",
      booktabs = TRUE,
      longtable = TRUE,
      linesep = "") %>%
  kable_styling(position = "center") %>% 
  column_spec(1,
              width = "3.5in",
              latex_valign = "m")
```

```{r test wrong preds table}
kable(test_wrong_preds,
      caption = "\\textbf{Test Set Misclassifications}",
      col.names = c("Sample Name", "True Class", "Predicted Class", "Probability"),
      row.names = FALSE,
      format = "latex",
      align = "l",
      booktabs = TRUE,
      longtable = TRUE,
      linesep = "") %>%
  kable_styling(position = "center") %>% 
  column_spec(1,
              width = "3.5in",
              latex_valign = "m")
```

\newpage
```{r train test data split}
## Add list of samples for training
train_samples <- sort(train_df$file_name)

## Add list of samples for testing
test_samples <- sort(test_df$file_name)

n <- max(length(train_samples), length(test_samples))
length(train_samples) <- n                      
length(test_samples) <- n

samples <- cbind("Training Samples" = train_samples,
                 "Test Samples" = test_samples)

samples[is.na(samples)] <- ""
```

```{r train test data split table}
kable(samples,
      caption = "\\textbf{Train/Test Data Split}",
      row.names = FALSE,
      format = "latex",
      align = "l",
      booktabs = TRUE,
      longtable = TRUE,
      linesep = "")
```
